{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting up remaining protein sequences to run to several lists to divy up locations to run things \n",
    "import numpy as np\n",
    "from os import path \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save embeddings for each fasta in the folder\n",
    "\n",
    "#setting up pytorch & trying the demos\n",
    "import torch\n",
    "from tape import ProteinBertModel, TAPETokenizer\n",
    "#unirep\n",
    "from tape import UniRepModel\n",
    "#getting the sweet, sweet < 2K AA proteins to use for the TAPE embeddings\n",
    "import string\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyensembl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import generic_protein\n",
    "from io import TextIOWrapper\n",
    "import time\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from queue import PriorityQueue\n",
    "from itertools import combinations\n",
    "from numpy.random import choice\n",
    "import random\n",
    "import sqlite3\n",
    "#from venn import venn\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "#actual Sqlite code for the database now\n",
    "dbName = \"interactionDB.sqlite3\"\n",
    "DEFAULT_PATH = os.path.join(os.path.dirname(\"./\"), dbName)\n",
    "\n",
    "\n",
    "def db_connect(db_path=DEFAULT_PATH):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    return con\n",
    "\n",
    "\n",
    "\n",
    "def getCDHitToEmbed(clusterFile, outputDir):\n",
    "    output = []\n",
    "    reps = []\n",
    "    with open(clusterFile, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines()]\n",
    "        for l in lines:\n",
    "            if \"*\" in l:\n",
    "                half = l.split(\">\")[1].translate(str.maketrans('', '', string.punctuation))\n",
    "                half = half.replace(\" \",\"\")\n",
    "                reps.append(half)\n",
    "    #get sequences from db\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    match = 0\n",
    "    notMatch = 0\n",
    "    seqs = []\n",
    "    print ('total len reps: ', len(reps))\n",
    "    for id in reps:\n",
    "        cur.execute(\"SELECT * FROM proteins WHERE id=?\", (id,))\n",
    "        fetched = cur.fetchall()\n",
    "        if len(fetched) == 1:\n",
    "            seqs.append(fetched[0][1])\n",
    "            output.append((fetched[0][0], fetched[0][1]))\n",
    "        else:\n",
    "            # print (\"OVER MATCHED\")\n",
    "            notMatch += 1\n",
    "    print (\"found: \", match)\n",
    "    print (\"not found: \", notMatch)\n",
    "    return seqs, output \n",
    "\n",
    "def createReps(clusterFile, outputDir):\n",
    "    seqs, output = getCDHitToEmbed(clusterFile, outputDir)\n",
    "    '''\n",
    "    for i in range(0, len(output)):# in output:\n",
    "        pair = output[i]\n",
    "        print (\"ON: \", i, \" OUT OF \", len(output))\n",
    "        print(\"len seq: \", len(pair[1]))\n",
    "        meanS1 = getTransformerMeanSequenceOutput(pair[1]).detach().numpy()\n",
    "        #print(meanS1.shape)\n",
    "        #print (type(meanS1))\n",
    "        #save npy file to the folder \n",
    "        np.save(\"./bert_base_embeddings/\" + str(pair[0]) + \".npy\", meanS1)\n",
    "        print (\"bert done\")\n",
    "    '''\n",
    "    output = output[::-1]\n",
    "    for i in range(0, len(output)):# in output:\n",
    "        pair = output[i]\n",
    "        print (\"ON: \", i, \" OUT OF \", len(output))\n",
    "        print(\"len seq: \", len(pair[1]))\n",
    "        if not path.exists(\"./unirep_embeddings/\" + str(pair[0]) + \".npy\"):\n",
    "            dummyFile = np.array([0])\n",
    "            np.save(\"./unirep_embeddings/\" + str(pair[0]) + \".npy\", dummyFile) #save temp blank file here to run mult copies of the script at once \n",
    "            uniRepPool = getUniRepPooledSequence(pair[1]).detach().numpy()\n",
    "            #print(uniRepPool.shape)\n",
    "            #print (type(uniRepPool))\n",
    "            np.save(\"./unirep_embeddings/\" + str(pair[0]) + \".npy\", uniRepPool)\n",
    "            print (\"unirep done\")\n",
    "        else:\n",
    "            print (\"exists\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total len reps:  16614\n",
      "found:  0\n",
      "not found:  0\n"
     ]
    }
   ],
   "source": [
    "#all outputs to run \n",
    "seqs, output = getCDHitToEmbed(\"embedPPI_50_2000_70_Cutoff.clstr\", \"./embedSeqs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16614\n"
     ]
    }
   ],
   "source": [
    "print (len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#those done \n",
    "done = []\n",
    "notDone = []\n",
    "for pair in output:\n",
    "    if not path.exists(\"./unirep_embeddings/\" + str(pair[0]) + \".npy\"):\n",
    "        notDone.append(pair[0])\n",
    "    else:\n",
    "        done.append(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15143\n",
      "1471\n"
     ]
    }
   ],
   "source": [
    "print (len(notDone))\n",
    "print (len(done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_structuralppi)",
   "language": "python",
   "name": "conda_structuralppi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
