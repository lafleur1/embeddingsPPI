{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#running PIPR from here, shell script will not detect CUDA devices \n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import sys\n",
    "if '../../embeddings' not in sys.path:\n",
    "    sys.path.append('../../embeddings')\n",
    "\n",
    "from seq2tensor import s2t\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, LSTM, Bidirectional, BatchNormalization, add\n",
    "from keras.layers.core import Flatten, Reshape\n",
    "from keras.layers.merge import Concatenate, concatenate, subtract, multiply\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D\n",
    "\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "def get_session(gpu_fraction=0.75):\n",
    "    '''Assume that you have 6GB of GPU memory and want to allocate ~2GB'''\n",
    "\n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "KTF.set_session(get_session())\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import Input, CuDNNGRU\n",
    "from numpy import linalg as LA\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change\n",
    "id2seq_file = '../../sun/preprocessed/SEQ-Supp-ABCD.tsv'\n",
    "\n",
    "id2index = {}\n",
    "seqs = []\n",
    "index = 0\n",
    "for line in open(id2seq_file):\n",
    "    line = line.strip().split('\\t')\n",
    "    id2index[line[0]] = index\n",
    "    seqs.append(line[1])\n",
    "    index += 1\n",
    "seq_array = []\n",
    "id2_aid = {}\n",
    "sid = 0\n",
    "\n",
    "seq_size = 600\n",
    "emb_files = ['../../embeddings/default_onehot.txt', '../../embeddings/string_vec5.txt', '../../embeddings/CTCoding_onehot.txt', '../../embeddings/vec7_CTC.txt']\n",
    "use_emb = 0\n",
    "hidden_dim = 25\n",
    "n_epochs=50\n",
    "\n",
    "# ds_file, label_index, rst_file, use_emb, hidden_dim\n",
    "ds_file = '../../yest/preprocessed/Supp-AB.tsv'\n",
    "label_index = 2\n",
    "rst_file = 'results/15k_onehot_cnn.txt'\n",
    "sid1_index = 0\n",
    "sid2_index = 1\n",
    "'''\n",
    "if len(sys.argv) > 1:\n",
    "    ds_file, label_index, rst_file, use_emb, hidden_dim, n_epochs = sys.argv[1:]\n",
    "    label_index = int(label_index)\n",
    "    use_emb = int(use_emb)\n",
    "    hidden_dim = int(hidden_dim)\n",
    "    n_epochs = int(n_epochs)\n",
    "'''\n",
    "#manually set these for the three diff networks tested \n",
    "#../../../sun/preprocessed/Supp-AB.tsv -1 results/sun_wvctc_rcnn_25_5.txt 3 25 100\n",
    "#../../../sun/preprocessed/Supp-AB.tsv -1 results/sun_wvctc_rcnn_50_5.txt 3 50 100\n",
    "#../../../sun/preprocessed/Supp-AB.tsv -1 results/sun_wvctc_rcnn_75_5.txt 3 75 100\n",
    "#best from the paper was hiden dim 50 \n",
    "ds_file = \"../../sun/preprocessed/Supp-AB.tsv\"\n",
    "label_index = -1\n",
    "rst_file = \"results/sun_wvctc_rcnn_50_5.txt\"\n",
    "use_emb = 3\n",
    "hidden_dim = 50\n",
    "n_epochs = 50\n",
    "seq2t = s2t(emb_files[use_emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73109it [00:00, 226348.86it/s]\n",
      "  2%|▏         | 237/10364 [00:00<00:04, 2357.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73108\n",
      "2 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10364/10364 [00:03<00:00, 2633.97it/s]\n",
      "100%|██████████| 73108/73108 [00:00<00:00, 963925.32it/s]\n",
      "100%|██████████| 73108/73108 [00:00<00:00, 987454.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  4  6  8 10 12 14 16 18]\n",
      "{'0': 1, '1': 0}\n",
      "3\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/MuPIPR_CLONE/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "65797/65797 [==============================] - 62s 946us/step - loss: 0.7228 - acc: 0.5236\n",
      "Epoch 2/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.6947 - acc: 0.5331\n",
      "Epoch 3/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.6895 - acc: 0.5556\n",
      "Epoch 4/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.6792 - acc: 0.5952\n",
      "Epoch 5/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.6083 - acc: 0.6716\n",
      "Epoch 6/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.3612 - acc: 0.8478\n",
      "Epoch 7/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.2299 - acc: 0.9122\n",
      "Epoch 8/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.1764 - acc: 0.9386\n",
      "Epoch 9/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.1334 - acc: 0.9553\n",
      "Epoch 10/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.1138 - acc: 0.9625\n",
      "Epoch 11/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.0978 - acc: 0.9692\n",
      "Epoch 12/50\n",
      "65797/65797 [==============================] - 63s 957us/step - loss: 0.0824 - acc: 0.9743\n",
      "Epoch 13/50\n",
      "65797/65797 [==============================] - 59s 897us/step - loss: 0.0761 - acc: 0.9762\n",
      "Epoch 14/50\n",
      "65797/65797 [==============================] - 65s 989us/step - loss: 0.0692 - acc: 0.9789\n",
      "Epoch 15/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0601 - acc: 0.9821\n",
      "Epoch 16/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0541 - acc: 0.9836\n",
      "Epoch 17/50\n",
      "65797/65797 [==============================] - 84s 1ms/step - loss: 0.0497 - acc: 0.9845\n",
      "Epoch 18/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0455 - acc: 0.9854\n",
      "Epoch 19/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0418 - acc: 0.9870\n",
      "Epoch 20/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.0405 - acc: 0.9876\n",
      "Epoch 21/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0371 - acc: 0.9882\n",
      "Epoch 22/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0353 - acc: 0.9884\n",
      "Epoch 23/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0324 - acc: 0.9898\n",
      "Epoch 24/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0302 - acc: 0.9904\n",
      "Epoch 25/50\n",
      "65797/65797 [==============================] - 57s 861us/step - loss: 0.0288 - acc: 0.9904\n",
      "Epoch 26/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0282 - acc: 0.9912\n",
      "Epoch 27/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0273 - acc: 0.9912\n",
      "Epoch 28/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0257 - acc: 0.9914\n",
      "Epoch 29/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0241 - acc: 0.9919\n",
      "Epoch 30/50\n",
      "65797/65797 [==============================] - 57s 861us/step - loss: 0.0229 - acc: 0.9922\n",
      "Epoch 31/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0225 - acc: 0.9928\n",
      "Epoch 32/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0221 - acc: 0.9931\n",
      "Epoch 33/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 34/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0201 - acc: 0.9931\n",
      "Epoch 35/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0186 - acc: 0.9938\n",
      "Epoch 36/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 37/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.0167 - acc: 0.9941\n",
      "Epoch 38/50\n",
      "65797/65797 [==============================] - 57s 867us/step - loss: 0.0151 - acc: 0.9949\n",
      "Epoch 39/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0165 - acc: 0.9948\n",
      "Epoch 40/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0145 - acc: 0.9951\n",
      "Epoch 41/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0151 - acc: 0.9948\n",
      "Epoch 42/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0142 - acc: 0.9955\n",
      "Epoch 43/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0141 - acc: 0.9956\n",
      "Epoch 44/50\n",
      "65797/65797 [==============================] - 57s 861us/step - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 45/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0129 - acc: 0.9957\n",
      "Epoch 46/50\n",
      "65797/65797 [==============================] - 77s 1ms/step - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 47/50\n",
      "65797/65797 [==============================] - 58s 885us/step - loss: 0.0129 - acc: 0.9959\n",
      "Epoch 48/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 49/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 50/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0122 - acc: 0.9962\n",
      "0.981261113390781 0.9871687587168759 0.974931129476584 0.975577026301664 0.9810117810117811 3.548676785606872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "65797/65797 [==============================] - 60s 916us/step - loss: 0.8219 - acc: 0.5442\n",
      "Epoch 2/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.6910 - acc: 0.5562\n",
      "Epoch 3/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.6818 - acc: 0.5733\n",
      "Epoch 4/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.6733 - acc: 0.6066\n",
      "Epoch 5/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.5444 - acc: 0.7290\n",
      "Epoch 6/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.3133 - acc: 0.8730\n",
      "Epoch 7/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.2053 - acc: 0.9248\n",
      "Epoch 8/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.1535 - acc: 0.9465\n",
      "Epoch 9/50\n",
      "65797/65797 [==============================] - 57s 870us/step - loss: 0.1207 - acc: 0.9600\n",
      "Epoch 10/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.1028 - acc: 0.9669\n",
      "Epoch 11/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0904 - acc: 0.9719\n",
      "Epoch 12/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.0789 - acc: 0.9753\n",
      "Epoch 13/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0695 - acc: 0.9789\n",
      "Epoch 14/50\n",
      "65797/65797 [==============================] - 61s 923us/step - loss: 0.0622 - acc: 0.9810\n",
      "Epoch 15/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0558 - acc: 0.9837\n",
      "Epoch 16/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0521 - acc: 0.9838\n",
      "Epoch 17/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0493 - acc: 0.9848\n",
      "Epoch 18/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0443 - acc: 0.9863\n",
      "Epoch 19/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.0412 - acc: 0.9870\n",
      "Epoch 20/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0395 - acc: 0.9872\n",
      "Epoch 21/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0363 - acc: 0.9885\n",
      "Epoch 22/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0348 - acc: 0.9885\n",
      "Epoch 23/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0325 - acc: 0.9893\n",
      "Epoch 24/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0309 - acc: 0.9901\n",
      "Epoch 25/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0290 - acc: 0.9897\n",
      "Epoch 26/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0281 - acc: 0.9907\n",
      "Epoch 27/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0261 - acc: 0.9912\n",
      "Epoch 28/50\n",
      "65797/65797 [==============================] - 57s 864us/step - loss: 0.0250 - acc: 0.9912\n",
      "Epoch 29/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0237 - acc: 0.9919\n",
      "Epoch 30/50\n",
      "65797/65797 [==============================] - 57s 863us/step - loss: 0.0220 - acc: 0.9926\n",
      "Epoch 31/50\n",
      "65797/65797 [==============================] - 57s 862us/step - loss: 0.0226 - acc: 0.9930\n",
      "Epoch 32/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0200 - acc: 0.9933\n",
      "Epoch 33/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0187 - acc: 0.9934\n",
      "Epoch 34/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0188 - acc: 0.9934\n",
      "Epoch 35/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0178 - acc: 0.9938\n",
      "Epoch 36/50\n",
      "65797/65797 [==============================] - 57s 867us/step - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 37/50\n",
      "65797/65797 [==============================] - 57s 865us/step - loss: 0.0166 - acc: 0.9946\n",
      "Epoch 38/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0171 - acc: 0.9944\n",
      "Epoch 39/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0167 - acc: 0.9948\n",
      "Epoch 40/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0155 - acc: 0.9947\n",
      "Epoch 41/50\n",
      "65797/65797 [==============================] - 57s 867us/step - loss: 0.0138 - acc: 0.9951\n",
      "Epoch 42/50\n",
      "65797/65797 [==============================] - 57s 868us/step - loss: 0.0167 - acc: 0.9954\n",
      "Epoch 43/50\n",
      "65797/65797 [==============================] - 57s 871us/step - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 44/50\n",
      "65797/65797 [==============================] - 58s 875us/step - loss: 0.0136 - acc: 0.9954\n",
      "Epoch 45/50\n",
      "65797/65797 [==============================] - 57s 866us/step - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 46/50\n",
      "65797/65797 [==============================] - 57s 871us/step - loss: 0.0141 - acc: 0.9956\n",
      "Epoch 47/50\n",
      "65797/65797 [==============================] - 57s 870us/step - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 48/50\n",
      "65797/65797 [==============================] - 57s 867us/step - loss: 0.0106 - acc: 0.9960\n",
      "Epoch 49/50\n",
      "65797/65797 [==============================] - 57s 871us/step - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 50/50\n",
      "65797/65797 [==============================] - 57s 871us/step - loss: 0.0107 - acc: 0.9966\n",
      "0.9809191629052113 0.9840549828178694 0.9777383228626059 0.9778140737716075 0.9808864835240118 3.5152854613623807\n",
      "Epoch 1/50\n",
      "65797/65797 [==============================] - 64s 972us/step - loss: 0.7261 - acc: 0.5303\n",
      "Epoch 2/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.6971 - acc: 0.5491\n",
      "Epoch 3/50\n",
      "65797/65797 [==============================] - 59s 902us/step - loss: 0.6865 - acc: 0.5707\n",
      "Epoch 4/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.6660 - acc: 0.6061\n",
      "Epoch 5/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.5222 - acc: 0.7464\n",
      "Epoch 6/50\n",
      "65797/65797 [==============================] - 59s 902us/step - loss: 0.3141 - acc: 0.8683\n",
      "Epoch 7/50\n",
      "65797/65797 [==============================] - 59s 898us/step - loss: 0.2125 - acc: 0.9197\n",
      "Epoch 8/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.1591 - acc: 0.9434\n",
      "Epoch 9/50\n",
      "65797/65797 [==============================] - 59s 902us/step - loss: 0.1264 - acc: 0.9575\n",
      "Epoch 10/50\n",
      "65797/65797 [==============================] - 60s 909us/step - loss: 0.1043 - acc: 0.9657\n",
      "Epoch 11/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0917 - acc: 0.9712\n",
      "Epoch 12/50\n",
      "65797/65797 [==============================] - 60s 904us/step - loss: 0.0794 - acc: 0.9755\n",
      "Epoch 13/50\n",
      "65797/65797 [==============================] - 59s 903us/step - loss: 0.0736 - acc: 0.9776\n",
      "Epoch 14/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0640 - acc: 0.9806\n",
      "Epoch 15/50\n",
      "65797/65797 [==============================] - 60s 904us/step - loss: 0.0603 - acc: 0.9817\n",
      "Epoch 16/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0520 - acc: 0.9846\n",
      "Epoch 17/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.0497 - acc: 0.9849\n",
      "Epoch 18/50\n",
      "65797/65797 [==============================] - 59s 900us/step - loss: 0.0449 - acc: 0.9863\n",
      "Epoch 19/50\n",
      "65797/65797 [==============================] - 60s 906us/step - loss: 0.0405 - acc: 0.9879\n",
      "Epoch 20/50\n",
      "65797/65797 [==============================] - 60s 907us/step - loss: 0.0388 - acc: 0.9879\n",
      "Epoch 21/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.0364 - acc: 0.9886\n",
      "Epoch 22/50\n",
      "65797/65797 [==============================] - 60s 914us/step - loss: 0.0331 - acc: 0.9895\n",
      "Epoch 23/50\n",
      "65797/65797 [==============================] - 60s 908us/step - loss: 0.0352 - acc: 0.9883\n",
      "Epoch 24/50\n",
      "65797/65797 [==============================] - 59s 898us/step - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 25/50\n",
      "65797/65797 [==============================] - 60s 908us/step - loss: 0.0286 - acc: 0.9910\n",
      "Epoch 26/50\n",
      "65797/65797 [==============================] - 60s 908us/step - loss: 0.0278 - acc: 0.9905\n",
      "Epoch 27/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0272 - acc: 0.9908\n",
      "Epoch 28/50\n",
      "65797/65797 [==============================] - 60s 908us/step - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 29/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.0242 - acc: 0.9918\n",
      "Epoch 30/50\n",
      "65797/65797 [==============================] - 59s 903us/step - loss: 0.0218 - acc: 0.9925\n",
      "Epoch 31/50\n",
      "65797/65797 [==============================] - 59s 903us/step - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 32/50\n",
      "65797/65797 [==============================] - 59s 903us/step - loss: 0.0216 - acc: 0.9931\n",
      "Epoch 33/50\n",
      "65797/65797 [==============================] - 59s 903us/step - loss: 0.0207 - acc: 0.9932\n",
      "Epoch 34/50\n",
      "65797/65797 [==============================] - 59s 903us/step - loss: 0.0196 - acc: 0.9935\n",
      "Epoch 35/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.0166 - acc: 0.9945\n",
      "Epoch 36/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0161 - acc: 0.9945\n",
      "Epoch 37/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0173 - acc: 0.9940\n",
      "Epoch 38/50\n",
      "65797/65797 [==============================] - 60s 906us/step - loss: 0.0159 - acc: 0.9944\n",
      "Epoch 39/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0166 - acc: 0.9944\n",
      "Epoch 40/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0163 - acc: 0.9948\n",
      "Epoch 41/50\n",
      "65797/65797 [==============================] - 59s 904us/step - loss: 0.0155 - acc: 0.9948\n",
      "Epoch 42/50\n",
      "65797/65797 [==============================] - 60s 906us/step - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 43/50\n",
      "65797/65797 [==============================] - 60s 905us/step - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 44/50\n",
      "65797/65797 [==============================] - 60s 906us/step - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 45/50\n",
      "65797/65797 [==============================] - 60s 906us/step - loss: 0.0140 - acc: 0.9956\n",
      "Epoch 46/50\n",
      "65797/65797 [==============================] - 60s 907us/step - loss: 0.0122 - acc: 0.9958\n",
      "Epoch 47/50\n",
      "65797/65797 [==============================] - 60s 907us/step - loss: 0.0113 - acc: 0.9962\n",
      "Epoch 48/50\n",
      "65797/65797 [==============================] - 60s 908us/step - loss: 0.0132 - acc: 0.9956\n",
      "Epoch 49/50\n",
      "65797/65797 [==============================] - 60s 907us/step - loss: 0.0116 - acc: 0.9965\n",
      "Epoch 50/50\n",
      "65797/65797 [==============================] - 60s 907us/step - loss: 0.0142 - acc: 0.9956\n",
      "0.9821729813523001 0.9859452507808194 0.9783064442621456 0.9784556893274192 0.9821109941895045 3.6439374474318322\n",
      "0.9821729813523001 0.9859452507808194 0.9783064442621456 0.9821109941895045\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/sun_wvctc_rcnn_50_5.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-389400a7e9c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrst_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\tprec='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\trecall='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\tspec='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\tf1='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\tmcc='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/sun_wvctc_rcnn_50_5.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_data = -1\n",
    "limit_data = max_data > 0\n",
    "raw_data = []\n",
    "skip_head = True\n",
    "x = None\n",
    "count = 0\n",
    "\n",
    "for line in tqdm(open(ds_file)):\n",
    "    if skip_head:\n",
    "        skip_head = False\n",
    "        continue\n",
    "    line = line.rstrip('\\n').rstrip('\\r').split('\\t')\n",
    "    if id2index.get(line[sid1_index]) is None or id2index.get(line[sid2_index]) is None:\n",
    "        continue\n",
    "    if id2_aid.get(line[sid1_index]) is None:\n",
    "        id2_aid[line[sid1_index]] = sid\n",
    "        sid += 1\n",
    "        seq_array.append(seqs[id2index[line[sid1_index]]])\n",
    "    line[sid1_index] = id2_aid[line[sid1_index]]\n",
    "    if id2_aid.get(line[sid2_index]) is None:\n",
    "        id2_aid[line[sid2_index]] = sid\n",
    "        sid += 1\n",
    "        seq_array.append(seqs[id2index[line[sid2_index]]])\n",
    "    line[sid2_index] = id2_aid[line[sid2_index]]\n",
    "    raw_data.append(line)\n",
    "    if limit_data:\n",
    "        count += 1\n",
    "        if count >= max_data:\n",
    "            break\n",
    "print (len(raw_data))\n",
    "\n",
    "\n",
    "len_m_seq = np.array([len(line.split()) for line in seq_array])\n",
    "avg_m_seq = int(np.average(len_m_seq)) + 1\n",
    "max_m_seq = max(len_m_seq)\n",
    "print (avg_m_seq, max_m_seq)\n",
    "\n",
    "dim = seq2t.dim\n",
    "seq_tensor = np.array([seq2t.embed_normalized(line, seq_size) for line in tqdm(seq_array)])\n",
    "\n",
    "seq_index1 = np.array([line[sid1_index] for line in tqdm(raw_data)])\n",
    "seq_index2 = np.array([line[sid2_index] for line in tqdm(raw_data)])\n",
    "\n",
    "print(seq_index1[:10])\n",
    "\n",
    "class_map = {'0':1,'1':0}\n",
    "print(class_map)\n",
    "class_labels = np.zeros((len(raw_data), 2))\n",
    "for i in range(len(raw_data)):\n",
    "    class_labels[i][class_map[raw_data[i][label_index]]] = 1.\n",
    "\n",
    "def build_model():\n",
    "    seq_input1 = Input(shape=(seq_size, dim), name='seq1')\n",
    "    seq_input2 = Input(shape=(seq_size, dim), name='seq2')\n",
    "    l1=Conv1D(hidden_dim, 3)\n",
    "    r1=Bidirectional(CuDNNGRU(hidden_dim, return_sequences=True))\n",
    "    l2=Conv1D(hidden_dim, 3)\n",
    "    r2=Bidirectional(CuDNNGRU(hidden_dim, return_sequences=True))\n",
    "    l3=Conv1D(hidden_dim, 3)\n",
    "    r3=Bidirectional(CuDNNGRU(hidden_dim, return_sequences=True))\n",
    "    l4=Conv1D(hidden_dim, 3)\n",
    "    r4=Bidirectional(CuDNNGRU(hidden_dim, return_sequences=True))\n",
    "    l5=Conv1D(hidden_dim, 3)\n",
    "    r5=Bidirectional(CuDNNGRU(hidden_dim, return_sequences=True))\n",
    "    l6=Conv1D(hidden_dim, 3)\n",
    "    s1=MaxPooling1D(3)(l1(seq_input1))\n",
    "    s1=concatenate([r1(s1), s1])\n",
    "    s1=MaxPooling1D(3)(l2(s1))\n",
    "    s1=concatenate([r2(s1), s1])\n",
    "    s1=MaxPooling1D(2)(l3(s1))\n",
    "    s1=concatenate([r3(s1), s1])\n",
    "    s1=MaxPooling1D(2)(l4(s1))\n",
    "    s1=concatenate([r4(s1), s1])\n",
    "    s1=MaxPooling1D(2)(l5(s1))\n",
    "    s1=concatenate([r5(s1), s1])\n",
    "    s1=l6(s1)\n",
    "    s1=GlobalAveragePooling1D()(s1)\n",
    "    s2=MaxPooling1D(3)(l1(seq_input2))\n",
    "    s2=concatenate([r1(s2), s2])\n",
    "    s2=MaxPooling1D(3)(l2(s2))\n",
    "    s2=concatenate([r2(s2), s2])\n",
    "    s2=MaxPooling1D(2)(l3(s2))\n",
    "    s2=concatenate([r3(s2), s2])\n",
    "    s2=MaxPooling1D(2)(l4(s2))\n",
    "    s2=concatenate([r4(s2), s2])\n",
    "    s2=MaxPooling1D(2)(l5(s2))\n",
    "    s2=concatenate([r5(s2), s2])\n",
    "    s2=l6(s2)\n",
    "    s2=GlobalAveragePooling1D()(s2)\n",
    "    merge_text = multiply([s1, s2])\n",
    "    x = Dense(hidden_dim, activation='linear')(merge_text)\n",
    "    x = keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    x = Dense(int((hidden_dim+7)/2), activation='linear')(x)\n",
    "    x = keras.layers.LeakyReLU(alpha=0.3)(x)\n",
    "    main_output = Dense(2, activation='softmax')(x)\n",
    "    merge_model = Model(inputs=[seq_input1, seq_input2], outputs=[main_output])\n",
    "    return merge_model\n",
    "\n",
    "batch_size1 = 512\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "tries = 3\n",
    "cur = 0\n",
    "recalls = []\n",
    "accuracy = []\n",
    "total = []\n",
    "total_truth = []\n",
    "train_test = []\n",
    "for train, test in kf.split(class_labels):\n",
    "    if np.sum(class_labels[train], 0)[0] > 0.8 * len(train) or np.sum(class_labels[train], 0)[0] < 0.2 * len(train):\n",
    "        continue\n",
    "    train_test.append((train, test))\n",
    "    cur += 1\n",
    "    if cur >= tries:\n",
    "        break\n",
    "\n",
    "print (len(train_test))\n",
    "\n",
    "#copy below\n",
    "num_hit = 0.\n",
    "num_total = 0.\n",
    "num_pos = 0.\n",
    "num_true_pos = 0.\n",
    "num_false_pos = 0.\n",
    "num_true_neg = 0.\n",
    "num_false_neg = 0.\n",
    "fold = 0\n",
    "modelName = \"modelHiddenDims\" + str(hidden_dim)\n",
    "for train, test in train_test:\n",
    "    merge_model = None\n",
    "    adam = Adam(lr=0.001, amsgrad=True, epsilon=1e-6)\n",
    "    rms = RMSprop(lr=0.001)\n",
    "    merge_model = build_model()\n",
    "    merge_model.compile(optimizer=rms, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    merge_model.fit([seq_tensor[seq_index1[train]], seq_tensor[seq_index2[train]]], class_labels[train], batch_size=batch_size1, epochs=n_epochs)\n",
    "    #result1 = merge_model.evaluate([seq_tensor1[test], seq_tensor2[test]], class_labels[test])\n",
    "    pred = merge_model.predict([seq_tensor[seq_index1[test]], seq_tensor[seq_index2[test]]])\n",
    "    for i in range(len(class_labels[test])):\n",
    "        num_total += 1\n",
    "        if np.argmax(class_labels[test][i]) == np.argmax(pred[i]):\n",
    "            num_hit += 1\n",
    "        if class_labels[test][i][0] > 0.:\n",
    "            num_pos += 1.\n",
    "            if pred[i][0] > pred[i][1]:\n",
    "                num_true_pos += 1\n",
    "            else:\n",
    "                num_false_neg += 1\n",
    "        else:\n",
    "            if pred[i][0] > pred[i][1]:\n",
    "                num_false_pos += 1\n",
    "            else:\n",
    "                num_true_neg += 1\n",
    "    accuracy = num_hit / num_total\n",
    "    prec = num_true_pos / (num_true_pos + num_false_pos)\n",
    "    recall = num_true_pos / num_pos\n",
    "    spec = num_true_neg / (num_true_neg + num_false_neg)\n",
    "    f1 = 2. * prec * recall / (prec + recall)\n",
    "    mcc = (num_true_pos * num_true_neg - num_false_pos * num_false_neg) / ((num_true_pos + num_true_neg) * (num_true_pos + num_false_neg) * (num_false_pos + num_true_neg) * (num_false_pos + num_false_neg)) ** 0.5\n",
    "    print (accuracy, prec, recall, spec, f1, mcc)\n",
    "    totalMName = modelName + \"fold\" + str(fold)\n",
    "    fold += 1\n",
    "    merge_model.save(totalMName)\n",
    "\n",
    "accuracy = num_hit / num_total\n",
    "prec = num_true_pos / (num_true_pos + num_false_pos)\n",
    "recall = num_true_pos / num_pos\n",
    "spec = num_true_neg / (num_true_neg + num_false_neg)\n",
    "f1 = 2. * prec * recall / (prec + recall)\n",
    "mcc = (num_true_pos * num_true_neg - num_false_pos * num_false_neg) / ((num_true_pos + num_true_neg) * (num_true_pos + num_false_neg) * (num_false_pos + num_true_neg) * (num_false_pos + num_false_neg)) ** 0.5\n",
    "print (accuracy, prec, recall, f1)\n",
    "\n",
    "with open(rst_file, 'w') as fp:\n",
    "    fp.write('acc=' + str(accuracy) + '\\tprec=' + str(prec) + '\\trecall=' + str(recall) + '\\tspec=' + str(spec) + '\\tf1=' + str(f1) + '\\tmcc=' + str(mcc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fold 0\n",
    "0.981261113390781 0.9871687587168759 0.974931129476584 0.975577026301664 0.9810117810117811 3.548676785606872\n",
    "#fold 1\n",
    "#0.9809191629052113 0.9840549828178694 0.9777383228626059 0.9778140737716075 0.9808864835240118 3.5152854613623807\n",
    "#fold 2\n",
    "#0.9821729813523001 0.9859452507808194 0.9783064442621456 0.9784556893274192 0.9821109941895045 3.6439374474318322\n",
    "0.9821729813523001 0.9859452507808194 0.9783064442621456 0.9821109941895045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_mupipr_clone)",
   "language": "python",
   "name": "conda_mupipr_clone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
