{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from io import TextIOWrapper\n",
    "import time\n",
    "import os.path\n",
    "from os import path\n",
    "from queue import PriorityQueue\n",
    "from itertools import combinations\n",
    "from numpy.random import choice\n",
    "import random\n",
    "import sqlite3\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#actual Sqlite code for the database now\n",
    "dbName = \"interactionDB.sqlite3\"\n",
    "DEFAULT_PATH = os.path.join(os.path.dirname(\"../\"), dbName)\n",
    "\n",
    "def db_connect(db_path=DEFAULT_PATH):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    return con\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def db_connect(db_path=DEFAULT_PATH):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    return con\n",
    "\n",
    "def getSequences():\n",
    "    #return the contents of the sequence table\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    with conn:\n",
    "        cur.execute(\"SELECT * FROM proteins\")\n",
    "        return cur.fetchall()\n",
    "\n",
    "def getAllInteractions():\n",
    "    # return the contents of the sequence table\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    with conn:\n",
    "        cur.execute(\"SELECT * FROM interaction\")\n",
    "        return cur.fetchall()\n",
    "\n",
    "\n",
    "\n",
    "def getSubsetInteractions(idList):\n",
    "    # return all interactions where both partners in idList\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM interaction\")\n",
    "    ints = cur.fetchall()\n",
    "    subset = []\n",
    "    for i in range(0, len(ints)):\n",
    "        int_potential = ints[i]\n",
    "        if i%1000 == 0:\n",
    "            print (\"ON: \", i, \" OUT OF \", len(ints))\n",
    "            print (len(subset))\n",
    "        #check each interaction partners if they are in the list of ids\n",
    "        #print (int_potential)\n",
    "        if int_potential[1] in idList and int_potential[2] in idList:\n",
    "            subset.append(int_potential)\n",
    "    return subset\n",
    "\n",
    "def resetAllSequenceLens():\n",
    "    #getting all sequences <= 2000 AA long\n",
    "    allseqs = getSequences()\n",
    "    ids = [x[0] for x in allseqs]\n",
    "    actualSeqs = [x[1] for x in allseqs]\n",
    "    lens = [len(x) for x in actualSeqs]\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    #set all sequence lengths\n",
    "    for i in range(0, len(ids)):\n",
    "        updateQuery = \"UPDATE proteins SET length=? WHERE id=?\"\n",
    "        cur.execute(updateQuery, (lens[i], ids[i]))\n",
    "        conn.commit()\n",
    "\n",
    "def proteinsInDBtoFastaForCDHit(lower, upper, saveName):\n",
    "    #convertes the SQL table to a fasta with my_ids as the name per sequence to run 40% CD-HIT on\n",
    "    #distinctProQuery = \"SELECT DISTINCT sequence FROM proteins\"\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    #query = cur.execute(distinctProQuery)\n",
    "    #fetched = query.fetchall()\n",
    "    #confirm that total size of db is same as unique number of seqs\n",
    "    allQuery = \"SELECT * FROM proteins WHERE length BETWEEN \" + str(lower) + \" AND \" + str(upper) #trRosetta trained on sequences <= upper and >= lower\n",
    "    allQuery = cur.execute(allQuery)\n",
    "    allFetched = allQuery.fetchall()\n",
    "    #if len(fetched) != len(allFetched):\n",
    "     #   print (\"stopping, duplicate sequences in teh table\")\n",
    "    #else:\n",
    "    print (\"writing all sequences to a fasta\")\n",
    "    print (len(allFetched))\n",
    "    #make into a large fasta file w/ CD-HIT\n",
    "    with open(saveName, \"w\") as f:\n",
    "        for result in allFetched:\n",
    "            f.write(\">\" + str(result[0]) + \"\\n\" + result[1] + \"\\n\" )\n",
    "\n",
    "\n",
    "def getClusterRepIDs(clusterFile):\n",
    "    #each rep has a * by the name\n",
    "    reps = []\n",
    "    with open(clusterFile, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines()]\n",
    "        for l in lines:\n",
    "            if \"*\" in l:\n",
    "                half = l.split(\">\")[1].translate(str.maketrans('', '', string.punctuation))\n",
    "                half = half.replace(\" \",\"\")\n",
    "                reps.append(half)\n",
    "    #change to ints\n",
    "    reps = [int(x) for x in reps]\n",
    "    return reps\n",
    "\n",
    "#todo: extract ids of CD-HIT clusters\n",
    "def getCDHIT(clusterFile, outputDir):\n",
    "    if not os.path.isdir(outputDir):\n",
    "        os.mkdir(outputDir)\n",
    "    #each rep has a * by the name\n",
    "    reps = []\n",
    "    with open(clusterFile, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines()]\n",
    "        for l in lines:\n",
    "            if \"*\" in l:\n",
    "                half = l.split(\">\")[1].translate(str.maketrans('', '', string.punctuation))\n",
    "                half = half.replace(\" \",\"\")\n",
    "                reps.append(half)\n",
    "    #get sequences from db\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    match = 0\n",
    "    notMatch = 0\n",
    "    seqs = []\n",
    "    print ('total len reps: ', len(reps))\n",
    "    for id in reps:\n",
    "        cur.execute(\"SELECT * FROM proteins WHERE id=?\", (id,))\n",
    "        fetched = cur.fetchall()\n",
    "        if len(fetched) == 1:\n",
    "            # add id to the my_ids table\n",
    "            # print (\"MATCHED\")\n",
    "            # id (generates automatically), database = str, database_name = str, my_id from proteins\n",
    "            seqs.append(fetched[0][1])\n",
    "            match += 1\n",
    "            with open(outputDir + id + \".fasta\", \"w\") as f:\n",
    "                f.write(\">\" + str(id) + \"\\n\" + fetched[0][1] + \"\\n\")\n",
    "        else:\n",
    "            # print (\"OVER MATCHED\")\n",
    "            notMatch += 1\n",
    "    print (\"found: \", match)\n",
    "    print (\"not found: \", notMatch)\n",
    "    return seqs\n",
    "\n",
    "\n",
    "#todo: extract ids of CD-HIT clusters\n",
    "def getCDHITOneFasta(clusterFile, fastaName):\n",
    "    #each rep has a * by the name\n",
    "    reps = []\n",
    "    with open(clusterFile, \"r\") as f:\n",
    "        lines = [x.strip() for x in f.readlines()]\n",
    "        for l in lines:\n",
    "            if \"*\" in l:\n",
    "                half = l.split(\">\")[1].translate(str.maketrans('', '', string.punctuation))\n",
    "                half = half.replace(\" \",\"\")\n",
    "                reps.append(half)\n",
    "    #get sequences from db\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    match = 0\n",
    "    notMatch = 0\n",
    "    seqs = []\n",
    "    print ('total len reps: ', len(reps))\n",
    "    outFasta = open(fastaName, \"w\")\n",
    "    for id in reps:\n",
    "        cur.execute(\"SELECT * FROM proteins WHERE id=?\", (id,))\n",
    "        fetched = cur.fetchall()\n",
    "        if len(fetched) == 1:\n",
    "            # add id to the my_ids table\n",
    "            # print (\"MATCHED\")\n",
    "            # id (generates automatically), database = str, database_name = str, my_id from proteins\n",
    "            seqs.append(fetched[0][1])\n",
    "            match += 1\n",
    "            outFasta.write(\">\" + str(id) + \"\\n\" + fetched[0][1] + \"\\n\")\n",
    "        else:\n",
    "            # print (\"OVER MATCHED\")\n",
    "            notMatch += 1\n",
    "    print (\"found: \", match)\n",
    "    print (\"not found: \", notMatch)\n",
    "    outFasta.close()\n",
    "    return seqs\n",
    "\n",
    "\n",
    "def getTransformerMeanSequenceOutput(seq):\n",
    "    #from github: pooled_output is *not* trained for the transformer\n",
    "    model = ProteinBertModel.from_pretrained('bert-base')\n",
    "    tokenizer = TAPETokenizer(vocab='iupac')  # iupac is the vocab for TAPE models, use unirep for the UniRep model\n",
    "    token_ids = torch.tensor([tokenizer.encode(seq)])\n",
    "    output = model(token_ids)\n",
    "    #average embedding for the bert model, average along sequence as recommendd\n",
    "    #output shape is (1,768)\n",
    "    return torch.mean(output[0],1)\n",
    "\n",
    "def getUniRepPooledSequence(sequence):\n",
    "    #return\n",
    "    model = UniRepModel.from_pretrained('babbler-1900')\n",
    "    token_ids = torch.tensor([tokenizer.encode(sequence)])\n",
    "    output = model(token_ids)\n",
    "    return output[1]\n",
    "\n",
    "\n",
    "def retrieveOrigNames(namesDone):\n",
    "    #retrieve count of proteins in HuRI\n",
    "    con = db_connect()\n",
    "    cur = con.cursor()\n",
    "    huRIMappedNames = []\n",
    "    for i in range(0, len(namesDone)):\n",
    "        name = namesDone[i]\n",
    "        if i % 1000 == 0:\n",
    "            print (\"ON \", i , \" OUT OF \", len(namesDone))\n",
    "        lookupQ = cur.execute(\"SELECT * FROM id_map WHERE database=? AND my_id=?\", (\"HuRI\", name))\n",
    "        fetched = lookupQ.fetchall()\n",
    "        if len(fetched) != 0:\n",
    "            #print (\"found match in HuRI!!!\")\n",
    "            huRIMappedNames.append(fetched[0][2])\n",
    "    #print (len(huRIMappedNames))\n",
    "    return huRIMappedNames\n",
    "\n",
    "def overlapTwoLists(list1, list2):\n",
    "    intersection = set(list1).intersection(set(list2))\n",
    "    return list(intersection)\n",
    "\n",
    "def lookAtPositivesAndNegativesCurrent(listIDs):\n",
    "    # looking at the number of positive examples with the cluster reps\n",
    "    cdHitSeqs = getClusterRepIDs(\"embedPPI_50_2000_70_Cutoff.clstr\")  # sequence IDs in the DB\n",
    "    # get all interactions\n",
    "    subsetGoodFor = getSubsetInteractions(cdHitSeqs)\n",
    "    positives = [x for x in subsetGoodFor if x[8] != 1]\n",
    "    print(len(positives))  # 279775\n",
    "    negatives = [x for x in subsetGoodFor if x[8] == 1]\n",
    "    print(len(negatives))  # 918\n",
    "    return positives, negatives\n",
    "\n",
    "\n",
    "\n",
    "def lookAtIntersection(huRIMappedNames):\n",
    "    #making negatives for HuRI interactions\n",
    "    print ('start ret')\n",
    "    in05 = open(\"./HuRI/HuRI_05_proteins.txt\", \"r\")\n",
    "    in05 = [x.strip() for x in in05.readlines()]\n",
    "    intersect1 = overlapTwoLists(huRIMappedNames, in05)\n",
    "    print(len(intersect1))\n",
    "    print(len(in05))\n",
    "    in14 = open(\"./HuRI/HuRI_14_proteins.txt\", \"r\")\n",
    "    in14 = [x.strip() for x in in14.readlines()]\n",
    "    intersect2 = overlapTwoLists(huRIMappedNames, in14)\n",
    "    print(len(intersect2))\n",
    "    print(len(in14))\n",
    "    in19 = open(\"./HuRI/HuRI_HuRI_proteins.txt\", \"r\")\n",
    "    in19 = [x.strip() for x in in19.readlines()]\n",
    "    intersect3 = overlapTwoLists(huRIMappedNames, in19)\n",
    "    print(len(intersect3))\n",
    "    print(len(in19))\n",
    "\n",
    "    #all HuRi pros\n",
    "    allHuRI = list(set(in05 + in14 + in19)) #all proteins\n",
    "    #print (allHuRI)\n",
    "    allIntersect = list(set(intersect1 + intersect2 + intersect3))\n",
    "    print (len(allIntersect))\n",
    "    # retrieve HuRI associated names to construct HuRI negatives\n",
    "    # print (namesDone)\n",
    "    return list(set(intersect1)), list(set(intersect2)), list(set(intersect3))\n",
    "\n",
    "def addEqualNumberNegativesToDB(cdHitSeqs, N):\n",
    "    #adds N negative HuRI interactiosn to the database based on number of positive interactions in the dataset\n",
    "    countAdded = 0\n",
    "    conn = db_connect()\n",
    "    cur = conn.cursor()\n",
    "    intersect1, intersect2, intersect3 = lookAtIntersection(cdHitSeqs)\n",
    "    int1_weight = len(intersect1)\n",
    "    int2_weight = len(intersect2)\n",
    "    int3_weight = len(intersect3)\n",
    "    total_weight = int1_weight + int2_weight + int3_weight\n",
    "    while countAdded < N: #keep adding until enough are reached\n",
    "        #select all-by-all\n",
    "        setIDs = random.choices([intersect1, intersect2, intersect3], weights = [int1_weight/total_weight, int2_weight/total_weight, int3_weight/total_weight])\n",
    "        #select two ids from set\n",
    "        #print (setIDs)\n",
    "        #print (len(setIDs))\n",
    "        #print (setIDs)\n",
    "        twoIDs = np.random.choice(setIDs[0], size = 2, replace=True)\n",
    "        #see if can get ids\n",
    "        cur.execute(\"SELECT * FROM id_map WHERE database=? AND database_name=?\", (\"HuRI\", twoIDs[0]))\n",
    "        fetched_a = cur.fetchall()\n",
    "        cur.execute(\"SELECT * FROM id_map WHERE database=? AND database_name=?\", (\"HuRI\", twoIDs[1]))\n",
    "        fetched_b = cur.fetchall()\n",
    "        ids = []\n",
    "        ids.append(fetched_a[0][3])\n",
    "        ids.append(fetched_b[0][3])\n",
    "        ids.sort()\n",
    "        #print (ids)\n",
    "        if len(fetched_a) == 1 and len(fetched_b) == 1:\n",
    "            # print (fetched_a, fetched_b)\n",
    "            # prep to add to interactions\n",
    "            # try to see if it already exists\n",
    "            search_interactions = \"SELECT * FROM interaction WHERE protein_1=? AND protein_2=?\"\n",
    "            cur.execute(search_interactions, (ids[0], ids[1]))\n",
    "            interaction_search = cur.fetchall()\n",
    "            if len(interaction_search) == 0:\n",
    "                id_map_sql = \"INSERT INTO interaction (protein_1, protein_2, huri_negative) VALUES (?,?,?)\"\n",
    "                cur.execute(id_map_sql, (ids[0], ids[1], True))\n",
    "                conn.commit()\n",
    "                countAdded += 1\n",
    "        if countAdded % 1000 == 0:\n",
    "            print(\"on: \", countAdded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdHitSeqs = getClusterRepIDs(\"../embedPPI_50_2000_70_Cutoff.clstr\") #sequence IDs in the DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ON  0  OUT OF  16614\n",
      "ON  1000  OUT OF  16614\n",
      "ON  2000  OUT OF  16614\n",
      "ON  3000  OUT OF  16614\n",
      "ON  4000  OUT OF  16614\n",
      "ON  5000  OUT OF  16614\n",
      "ON  6000  OUT OF  16614\n",
      "ON  7000  OUT OF  16614\n",
      "ON  8000  OUT OF  16614\n",
      "ON  9000  OUT OF  16614\n",
      "ON  10000  OUT OF  16614\n",
      "ON  11000  OUT OF  16614\n",
      "ON  12000  OUT OF  16614\n",
      "ON  13000  OUT OF  16614\n",
      "ON  14000  OUT OF  16614\n",
      "ON  15000  OUT OF  16614\n",
      "ON  16000  OUT OF  16614\n",
      "6655\n"
     ]
    }
   ],
   "source": [
    "huRIMappedNames = retrieveOrigNames(cdHitSeqs)\n",
    "print(len(huRIMappedNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ret\n",
      "805\n",
      "1178\n",
      "2711\n",
      "4078\n",
      "5398\n",
      "7307\n",
      "5901\n",
      "on:  1000\n",
      "on:  2000\n",
      "on:  3000\n",
      "on:  4000\n",
      "on:  5000\n",
      "on:  6000\n",
      "on:  7000\n",
      "on:  8000\n",
      "on:  9000\n",
      "on:  10000\n",
      "on:  11000\n",
      "on:  12000\n",
      "on:  13000\n",
      "on:  14000\n",
      "on:  15000\n",
      "on:  16000\n",
      "on:  17000\n",
      "on:  18000\n",
      "on:  19000\n",
      "on:  20000\n",
      "on:  21000\n",
      "on:  22000\n",
      "on:  23000\n",
      "on:  24000\n",
      "on:  25000\n",
      "on:  26000\n",
      "on:  27000\n",
      "on:  28000\n",
      "on:  29000\n",
      "on:  30000\n",
      "on:  31000\n",
      "on:  32000\n",
      "on:  33000\n",
      "on:  34000\n",
      "on:  35000\n",
      "on:  36000\n",
      "on:  37000\n",
      "on:  38000\n",
      "on:  39000\n",
      "on:  40000\n",
      "on:  41000\n",
      "on:  42000\n",
      "on:  43000\n",
      "on:  44000\n",
      "on:  45000\n",
      "on:  46000\n",
      "on:  47000\n",
      "on:  48000\n",
      "on:  49000\n",
      "on:  50000\n",
      "on:  51000\n",
      "on:  52000\n",
      "on:  53000\n",
      "on:  54000\n",
      "on:  55000\n",
      "on:  56000\n",
      "on:  57000\n",
      "on:  58000\n",
      "on:  59000\n",
      "on:  60000\n",
      "on:  61000\n",
      "on:  62000\n",
      "on:  63000\n",
      "on:  64000\n",
      "on:  65000\n",
      "on:  66000\n",
      "on:  67000\n",
      "on:  68000\n",
      "on:  69000\n",
      "on:  70000\n",
      "on:  71000\n",
      "on:  72000\n",
      "on:  73000\n",
      "on:  74000\n",
      "on:  75000\n",
      "on:  76000\n",
      "on:  77000\n",
      "on:  78000\n",
      "on:  79000\n",
      "on:  80000\n",
      "on:  81000\n",
      "on:  82000\n",
      "on:  83000\n",
      "on:  84000\n",
      "on:  85000\n",
      "on:  86000\n",
      "on:  87000\n",
      "on:  88000\n",
      "on:  89000\n",
      "on:  90000\n",
      "on:  91000\n",
      "on:  92000\n",
      "on:  93000\n",
      "on:  94000\n",
      "on:  95000\n",
      "on:  96000\n",
      "on:  97000\n",
      "on:  98000\n",
      "on:  99000\n",
      "on:  100000\n",
      "on:  101000\n",
      "on:  102000\n",
      "on:  103000\n",
      "on:  104000\n",
      "on:  105000\n",
      "on:  106000\n",
      "on:  107000\n",
      "on:  108000\n",
      "on:  109000\n",
      "on:  110000\n",
      "on:  111000\n",
      "on:  112000\n",
      "on:  113000\n",
      "on:  114000\n",
      "on:  115000\n",
      "on:  116000\n",
      "on:  117000\n",
      "on:  118000\n",
      "on:  119000\n",
      "on:  120000\n",
      "on:  121000\n",
      "on:  122000\n",
      "on:  123000\n",
      "on:  124000\n",
      "on:  125000\n",
      "on:  126000\n",
      "on:  127000\n",
      "on:  128000\n",
      "on:  129000\n",
      "on:  130000\n",
      "on:  131000\n",
      "on:  132000\n",
      "on:  133000\n",
      "on:  134000\n",
      "on:  135000\n",
      "on:  136000\n",
      "on:  137000\n",
      "on:  138000\n",
      "on:  139000\n",
      "on:  140000\n",
      "on:  141000\n",
      "on:  142000\n",
      "on:  143000\n",
      "on:  144000\n",
      "on:  145000\n",
      "on:  146000\n",
      "on:  147000\n",
      "on:  148000\n",
      "on:  149000\n",
      "on:  150000\n",
      "on:  151000\n",
      "on:  152000\n",
      "on:  153000\n",
      "on:  154000\n",
      "on:  155000\n",
      "on:  156000\n",
      "on:  157000\n",
      "on:  158000\n",
      "on:  159000\n",
      "on:  160000\n",
      "on:  161000\n",
      "on:  162000\n",
      "on:  163000\n",
      "on:  164000\n",
      "on:  165000\n",
      "on:  166000\n",
      "on:  167000\n",
      "on:  168000\n",
      "on:  169000\n",
      "on:  170000\n",
      "on:  171000\n",
      "on:  172000\n",
      "on:  173000\n",
      "on:  174000\n",
      "on:  175000\n",
      "on:  176000\n",
      "on:  177000\n",
      "on:  178000\n",
      "on:  179000\n",
      "on:  180000\n",
      "on:  181000\n",
      "on:  182000\n",
      "on:  183000\n",
      "on:  184000\n",
      "on:  185000\n",
      "on:  186000\n",
      "on:  187000\n",
      "on:  188000\n",
      "on:  189000\n",
      "on:  190000\n",
      "on:  191000\n",
      "on:  192000\n",
      "on:  193000\n",
      "on:  194000\n",
      "on:  195000\n",
      "on:  196000\n",
      "on:  197000\n",
      "on:  198000\n",
      "on:  199000\n",
      "on:  200000\n",
      "on:  201000\n",
      "on:  202000\n",
      "on:  203000\n",
      "on:  204000\n",
      "on:  205000\n",
      "on:  206000\n",
      "on:  207000\n",
      "on:  208000\n",
      "on:  209000\n",
      "on:  210000\n",
      "on:  211000\n",
      "on:  212000\n",
      "on:  213000\n",
      "on:  214000\n",
      "on:  215000\n",
      "on:  216000\n",
      "on:  217000\n",
      "on:  217000\n",
      "on:  218000\n",
      "on:  219000\n",
      "on:  220000\n",
      "on:  221000\n",
      "on:  222000\n",
      "on:  223000\n",
      "on:  224000\n",
      "on:  225000\n",
      "on:  226000\n",
      "on:  227000\n",
      "on:  228000\n",
      "on:  229000\n",
      "on:  230000\n",
      "on:  231000\n",
      "on:  232000\n",
      "on:  233000\n",
      "on:  234000\n",
      "on:  235000\n",
      "on:  236000\n",
      "on:  237000\n",
      "on:  238000\n",
      "on:  239000\n",
      "on:  240000\n",
      "on:  241000\n",
      "on:  242000\n",
      "on:  243000\n",
      "on:  244000\n",
      "on:  245000\n",
      "on:  246000\n",
      "on:  247000\n",
      "on:  248000\n",
      "on:  249000\n",
      "on:  250000\n",
      "on:  251000\n",
      "on:  252000\n",
      "on:  253000\n",
      "on:  254000\n",
      "on:  255000\n",
      "on:  256000\n",
      "on:  257000\n",
      "on:  258000\n",
      "on:  259000\n",
      "on:  260000\n",
      "on:  261000\n",
      "on:  262000\n",
      "on:  263000\n",
      "on:  264000\n",
      "on:  265000\n",
      "on:  266000\n",
      "on:  267000\n",
      "on:  268000\n",
      "on:  269000\n",
      "on:  270000\n",
      "on:  271000\n",
      "on:  272000\n",
      "on:  273000\n",
      "on:  274000\n",
      "on:  275000\n",
      "on:  276000\n",
      "on:  277000\n",
      "on:  278000\n",
      "on:  279000\n"
     ]
    }
   ],
   "source": [
    "#lookAtIntersection(cdHitSeqs)\n",
    "addEqualNumberNegativesToDB(huRIMappedNames, 279058) #need exactly 279775 - 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = db_connect()\n",
    "cur = conn.cursor()\n",
    "del1 = \"DELETE FROM interaction WHERE huri_negative=1\"\n",
    "cur.execute(del1)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
